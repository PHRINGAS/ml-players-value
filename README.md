# Predictive System for Football Player Valuation (v1.0)

This repository documents the construction of an end-to-end Machine Learning system for estimating football players' market value. The project spans from data ingestion and cleaning to model training, optimization, and packaging of a production-ready predictive model.

---

## ğŸ¯ The Challenge: The Hidden Value in Data

Football player valuation is a complex process with millions of euros at stake in every market decision. While scouts and analysts bring invaluable experience, the process often lacks an objective, quantifiable foundation.

This project addresses the following challenge: **Is it possible to build a model that learns hidden patterns in data to estimate a player's market value, based on their performance, demographic profile, and crucially, their competitive context?**

## âœ¨ Key Results: An Intelligent and Quantifiable Model

After a rigorous iterative modeling process, the final system can predict market value with a **Mean Absolute Error (MAE) of â‚¬2,921,504**.

- **Massive Improvement:** This represents a **26.63% error reduction** (more than â‚¬1,060,000 in added precision) compared to the initial baseline model.
- **Contextual Intelligence:** Feature importance analysis revealed that the most determining factors are not just goals or assists, but the **player's context**:
  1. **Contract Situation** (`contract_months_remaining`)
  2. **Age and Potential** (`age`)
  3. **Competition Quality** (`league_strength_factor`)
  4. **Club Prestige** (`club_tier`)

## ğŸ—ï¸ The Process: From Raw Data to Predictive Model

The project's success is based on an iterative approach where each phase built upon the previous:

1. **Foundations and Baseline:** We established a robust ETL process to clean and unify multiple data sources. A simple Ridge Regression model set our baseline with an **MAE of â‚¬3.98M**.
2. **Feature Engineering (Iteration 1):** We created normalized performance features (e.g., `goals_per_90`) and business features (e.g., `contract_months_remaining`). This allowed a base LightGBM model to reduce MAE to **â‚¬3.23M**, an 18.7% improvement.
3. **Hyperparameter Optimization:** Using **Optuna**, we conducted an exhaustive search (300 trials) to find the optimal LightGBM configuration, refining its performance and robustness.
4. **Error Analysis and the "Context Factor" (Iteration 2):** We analyzed where the model failed, discovering systematic underestimation of elite players and overestimation of players in minor leagues. This guided the creation of **contextual features** (`league_strength_factor`, `club_tier`), leading the final model to its **â‚¬2.92M MAE**, the definitive qualitative leap.

## ğŸ› ï¸ Technology Stack

- **Analysis and Modeling:** Python, Pandas, Scikit-learn, LightGBM
- **Configuration and Validation:** YAML (configs), Pydantic for input validation
- **Data/Model Versioning:** DVC (Data Version Control) with `dvc.yaml`
- **Environment and Prototyping:** Jupyter Notebooks (development) and modular `.py` scripts (production)
- **Interface:** CLI with Typer; optional API with FastAPI + Uvicorn
- **Quality/Automation:** pre-commit (black/ruff/isort/nbstripout), GitHub Actions (CI), Pytest
- **Hyperparameter Optimization (optional):** Optuna

## ğŸ“ Repository Structure

```
â”œâ”€â”€ data/                                  # Directory for all datasets (managed by DVC)
â”‚   â”œâ”€â”€ raw/                               # Original, unmodified data
â”‚   â””â”€â”€ processed/                         # Clean and enriched datasets, ready for modeling
â”‚
â”œâ”€â”€ models/                                # Model artifacts
â”‚   â”œâ”€â”€ lgbm_final_context_model.pkl       # Serialized model
â”‚   â”œâ”€â”€ model_columns.json                 # Expected features list (order)
â”‚   â”œâ”€â”€ metrics.json                       # Global metrics (MAE)
â”‚   â””â”€â”€ feature_importances.csv            # Feature importances
â”‚
â”œâ”€â”€ notebooks/                             # Exploration and development process (Jupyter Notebooks)
â”‚   â”œâ”€â”€ 00_baselines.ipynb
â”‚   â”œâ”€â”€ 01_eda_cariboo_dataset.ipynb
â”‚   â”œâ”€â”€ 02_feature_engineering.ipynb
â”‚   â”œâ”€â”€ 03_modeling.ipynb
â”‚   â”œâ”€â”€ 04_hyperparameter_tuning.ipynb
â”‚   â”œâ”€â”€ 05_error_analysis.ipynb
â”‚   â”œâ”€â”€ 06_contextual_feature_engineering.ipynb
â”‚   â”œâ”€â”€ 07_final_model_evaluation.ipynb
â”‚   â””â”€â”€ 08_final_error_analysis.ipynb
â”‚
â”œâ”€â”€ src/                                   # Production source code
â”‚   â”œâ”€â”€ etl/
â”‚   â”‚   â””â”€â”€ build_master_dataset.py        # ETL from raw tables â†’ master
â”‚   â”œâ”€â”€ features/
â”‚   â”‚   â””â”€â”€ build_features.py              # Contextual feature engineering (production)
â”‚   â”œâ”€â”€ validation/
â”‚   â”‚   â””â”€â”€ validate_master.py             # Master dataset validation (Pandera)
â”‚   â”œâ”€â”€ monitoring/
â”‚   â”‚   â””â”€â”€ drift_report.py                # Drift report (Evidently)
â”‚   â”œâ”€â”€ predictor.py                       # Predictor with Pydantic + external configuration (YAML)
â”‚   â”œâ”€â”€ train.py                           # Final model training
â”‚   â””â”€â”€ evaluate.py                        # Global and segment evaluation
â”‚
â”œâ”€â”€ configs/                               # Versioned configuration (YAML)
â”‚   â”œâ”€â”€ context.yaml                       # League strength map and tier-1 clubs
â”‚   â””â”€â”€ hparams.yaml                       # LightGBM hyperparameters and split
â”‚
â”œâ”€â”€ .gitignore
â”œâ”€â”€ README.md                              # This file
â”œâ”€â”€ requirements-dev.txt                   # Development/training dependencies
â”œâ”€â”€ requirements-prod.txt                  # Minimal production/inference dependencies
â”œâ”€â”€ dvc.yaml                               # DVC pipeline (ETL â†’ features â†’ train â†’ evaluate)
â”œâ”€â”€ Dockerfile                             # Image for serving the API
â”œâ”€â”€ .dockerignore                          # Docker image exclusions
â”œâ”€â”€ .pre-commit-config.yaml                # Quality hooks (black/ruff/isort/nbstripout)
â”œâ”€â”€ pyproject.toml                         # Linter/formatter configuration
â”œâ”€â”€ .github/workflows/ci.yml               # CI pipeline (lint + tests)
â””â”€â”€ scoping.md                             # Project scope document
```

## ğŸš€ How to Run the Project

Follow these instructions for reproducibility (ETL â†’ features â†’ train â†’ evaluate) and inference (CLI / API / Docker).

### Prerequisites

- Python 3.10+
- Git
- DVC installed (`pip install dvc`) or install from `requirements-dev.txt`

### 1) Environment Setup

```bash
python -m venv venv
# Windows
venv\Scripts\activate
# Linux/Mac
# source venv/bin/activate

# Development/training
pip install -r requirements-dev.txt

# Production/inference (minimal)
# pip install -r requirements-prod.txt
```

### 2) Get Data and Reproduce Pipeline

```bash
dvc pull

dvc repro
```

Generated artifacts:

- `data/processed/master_player_dataset.csv`
- `data/processed/contextual_featured_dataset.csv`
- `models/lgbm_final_context_model.pkl`, `models/model_columns.json`
- `models/metrics.json`, `models/feature_importances.csv`
- `models/metrics_by_segment.json`

### 3) Script Inference (Demo)

```bash
python src/predictor.py
```

Optional environment variables:

- `MODEL_PATH` (default: `models/lgbm_final_context_model.pkl`)
- `COLUMNS_PATH` (default: `models/model_columns.json`)

### 4) CLI (Typer)

```bash
python -m src.cli predict --age 22.5 --height-in-cm 185 \
  --current-club-name "Bayer 04 Leverkusen" \
  --player-club-domestic-competition-id DE1 \
  --minutes-played 2800 --goals 15 --assists 10 \
  --contract-months-remaining 36
```

Or with a JSON input file:

```bash
python -m src.cli predict --input player.json
```

### 5) API (FastAPI)

```bash
uvicorn src.api:app --host 0.0.0.0 --port 8000
```

Test:

- Health: http://localhost:8000/healthz
- Prediction (POST http://localhost:8000/predict)

Example payload:

```json
{
  "age": 22.5,
  "height_in_cm": 185,
  "current_club_name": "Bayer 04 Leverkusen",
  "player_club_domestic_competition_id": "DE1",
  "minutes_played": 2800,
  "goals": 15,
  "assists": 10,
  "contract_months_remaining": 36
}
```

### 6) Docker

```bash
docker build -t players-value:latest .
docker run --rm -p 8000:8000 players-value:latest
```

### 7) Quality and Testing

```bash
pre-commit install
pre-commit run --all-files
pytest -q
```

### 8) Validation and Monitoring

```bash
python -m src.validation.validate_master

python -m src.monitoring.drift_report \
  data/processed/contextual_featured_dataset.csv \
  data/processed/contextual_featured_dataset.csv \
  --output reports/drift_report.html
```

---

For training or retraining details, consult `src/train.py` and `configs/hparams.yaml`. To adjust context (league strength, tier-1 clubs), edit `configs/context.yaml`.
