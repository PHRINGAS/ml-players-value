# Hyperparameters and training config for LightGBM model
random_state: 42
test_size: 0.2

lgbm:
  objective: regression
  metric: mae
  n_estimators: 2000
  learning_rate: 0.03
  num_leaves: 63
  max_depth: -1
  min_child_samples: 20
  subsample: 0.8
  subsample_freq: 1
  colsample_bytree: 0.9
  reg_alpha: 0.0
  reg_lambda: 0.0
  n_jobs: -1
  verbosity: -1
  # early stopping is configured in train.py via callback/parameters
